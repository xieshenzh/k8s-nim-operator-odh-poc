apiVersion: apps.nvidia.com/v1alpha1
kind: NIMService
metadata:
  name: meta-llama3-8b-instruct
  namespace: nim-service
spec:
  nodeSelector:
    node.kubernetes.io/instance-type: p4d.24xlarge
  metrics:
    serviceMonitor: {}
  expose:
    ingress:
      enabled: true
      spec:
        rules:
          - host: meta-llama3-8b-instruct.apps.ai-dev03.kni.syseng.devcluster.openshift.com
            http:
              paths:
                - backend:
                    service:
                      name: meta-llama3-8b-instruct
                      port:
                        number: 8000
                  path: /v1/chat/completions
                  pathType: Prefix
    service:
      port: 8000
      type: ClusterIP
  resources:
    limits:
      cpu: "12"
      memory: 32Gi
      nvidia.com/gpu: '1'
    requests:
      cpu: "12"
      memory: 32Gi
      nvidia.com/gpu: '1'
  readinessProbe: {}
  scale:
    enabled: true
    hpa:
      minReplicas: 1
      maxReplicas: 10
  livenessProbe: {}
  startupProbe: {}
  authSecret: ngc-api-secret
  image:
    pullPolicy: IfNotPresent
    pullSecrets:
      - ngc-secret
    repository: nvcr.io/nim/meta/llama3-8b-instruct
    tag: 1.0.3
  storage:
    nimCache:
      name: meta-llama3-8b-instruct
      profile: '8835c31752fbc67ef658b20a9f78e056914fdef0660206d82f252d62fd96064d'
  replicas: 1
  tolerations:
    - effect: NoSchedule
      key: p4-gpu
      operator: Exists